import InvokeAgent as agenthelper
import streamlit as st
import json
import pandas as pd
from PIL import Image, ImageOps, ImageDraw

st.write("theRegion", st.secrets["AWS_REGION"])

# Streamlit page configuration
st.set_page_config(page_title="Verdigris Chatbot", page_icon=":robot_face:", layout="wide")

# Function to crop image into a circle
def crop_to_circle(image):
    mask = Image.new('L', image.size, 0)
    mask_draw = ImageDraw.Draw(mask)
    mask_draw.ellipse((0, 0) + image.size, fill=255)
    result = ImageOps.fit(image, mask.size, centering=(0.5, 0.5))
    result.putalpha(mask)
    return result

# Title with logo
col1, col2 = st.columns([1, 5])
with col1:
    st.image("verdigris_logo.png", width=100)
with col2:
    st.title("Verdigris Chatbot")
    st.write("")  # Add a blank line
    st.write("")  # Add a blank line
    st.write("")  # Add a blank line

# Sidebar for user trace data
st.sidebar.title("Trace Data")

# Session State Management
if 'history' not in st.session_state:
    st.session_state['history'] = []
if 'prompt' not in st.session_state:
    st.session_state['prompt'] = ""
if 'reset_selectbox' not in st.session_state:
    st.session_state['reset_selectbox'] = False

knowledge_base_prompts = [
    "",
    "Does your device support 3-phase panels?",
    "Tell me about distinguished technologies of Verdigris",
    "What is the advantage of using Verdigris?",
    "Provide any important information I should know about Verdigris",
    "What is adaptive automation?",
    "Does Verdigris work in my country?",
    "Can I change use categories in the admin console?",
]

# Callback function to reset the selectbox and clear the input text area after processing
def reset_inputs():
    st.session_state['reset_selectbox'] = True
    st.session_state['selectbox_prompt'] = ""  # Reset the selectbox to the first (empty) option
    st.session_state['prompt'] = ""  # Clear the input text area

# Add a select box for knowledge base prompts
selected_prompt = st.selectbox(
    "Frequently asked questions",
    knowledge_base_prompts,
    key="selectbox_prompt",
    index=0 if st.session_state['reset_selectbox'] else knowledge_base_prompts.index(st.session_state['prompt']),
    placeholder="Choose an option"
)

# When a prompt is selected, populate it into the text input box
if selected_prompt:
    st.session_state['prompt'] = selected_prompt

# Display a text box for input
st.write("## Type your Question")
prompt = st.text_input("", max_chars=2000, value=st.session_state['prompt'], key="input_prompt")
prompt = prompt.strip()

# Display a primary button for submission
submit_button = st.button("Submit", type="primary")

# Display a button to end the session
end_session_button = st.button("End Session")

# Function to calculate dynamic height for responses
def calculate_text_area_height(text, min_height=100, max_height=400):
    lines = text.count("\n") + 5
    estimated_height = min(max_height, max(min_height, lines * 40))
    return estimated_height

# Handling user input and responses
if submit_button and prompt:
    event = {
        "sessionId": "MYSESSION115",
        "question": prompt
    }
    with st.spinner('I am generating the answer...'):
        captured_string, llm_response, metadata_list = agenthelper.askQuestion(event['question'], event['sessionId'])

    if llm_response:
        # Check if metadata_list is a list and contains data
        if isinstance(metadata_list, list) and metadata_list:
            urls_text = "\n"+"\nThis answer is generated by referring to our company documentation below.\n\nFeel free to ask follow-up questions or see the references:\n"
            for item in metadata_list:
                urls_text += f"- **{item['title']}** [Link]({item['url']})\n"
        else:
            urls_text = "\n"+"\n"+"\n\nThis answer does not contain references from our documentation. \n\n please contact support@verdigri.co for confirming the credibility of the content or ask more questions.\n"
        llm_response += urls_text

        st.session_state['history'].append({"question": prompt, "answer": llm_response})
        st.sidebar.text_area("Trace Output", value=captured_string, height=300)
    else:
        st.session_state['history'].append({"question": prompt, "answer": "No response received."})


# Display conversation history
st.write("## Conversation History")

# Load images outside the loop to optimize performance
human_image = Image.open('human_face.png')
robot_image = Image.open('verdigrisChar.jpg')
circular_human_image = crop_to_circle(human_image)
circular_robot_image = crop_to_circle(robot_image)

for index, chat in enumerate(reversed(st.session_state['history'])):
    col1_q, col2_q = st.columns([2, 10])
    with col1_q:
        st.image(circular_human_image, width=125)
    with col2_q:
        st.text_area("Q:", value=chat["question"], height=50, key=f"question_{index}", disabled=True)

    col1_a, col2_a = st.columns([2, 10])
    if isinstance(chat["answer"], pd.DataFrame):
        with col1_a:
            st.image(circular_robot_image, width=100)
        with col2_a:
            st.dataframe(chat["answer"], key=f"answer_df_{index}")
    else:
        answer_height = calculate_text_area_height(chat["answer"])
        with col1_a:
            st.image(circular_robot_image, width=150)
        with col2_a:
            st.markdown(
                f"<div style='height: {answer_height}px; overflow-y: auto;'>{chat['answer']}</div>",
                unsafe_allow_html=True
            )
